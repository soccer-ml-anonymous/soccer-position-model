# -*- coding: utf-8 -*-
"""StatsBombから選手個人のW杯のヒートマップを描く3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KqpJNR3HeR0WHxMN4U0QSUSDq0m1zyK8

# 🔹 1. 必要なライブラリのインストール
"""

!pip install statsbombpy kloppy seaborn matplotlib pandas

"""# 🔹2.Statsbomb open dataに含まれる大会を出力して確認す

"""

import pandas as pd
import requests

# StatsBomb Open Dataのcompetitions.jsonのURL
url = "https://raw.githubusercontent.com/statsbomb/open-data/master/data/competitions.json"

# JSONデータを取得
response = requests.get(url)
competitions = response.json()

# pandasでDataFrameに変換
df = pd.DataFrame(competitions)

# 必要なカラムだけ抽出（任意）
df = df[["competition_id", "season_id", "competition_name", "country_name", "season_name"]]

# CSVとして保存
df.to_csv("competitions.csv", index=False)

# 表示（確認用）
df.head()

"""# 🔹 3. W杯のIDを確認してイベントデータを取得


"""

import requests
import os
import json
from tqdm import tqdm

# 正しいID
competition_id = 43
season_id = 106

# 試合一覧を取得
matches_url = f"https://raw.githubusercontent.com/statsbomb/open-data/master/data/matches/{competition_id}/{season_id}.json"
matches = requests.get(matches_url).json()

# 保存フォルダ作成
os.makedirs("fifa_wc_2022_events", exist_ok=True)

# 各試合のイベントデータを取得
for match in tqdm(matches):
    match_id = match["match_id"]
    events_url = f"https://raw.githubusercontent.com/statsbomb/open-data/master/data/events/{match_id}.json"
    events = requests.get(events_url).json()

    # JSONとして保存
    with open(f"fifa_wc_2022_events/{match_id}.json", "w") as f:
        json.dump(events, f)

print("全試合のイベントデータを保存しました。")

import shutil

# フォルダをZIPファイルに圧縮
shutil.make_archive("fifa_wc_2022_events", 'zip', "fifa_wc_2022_events")
from google.colab import files
# ZIPファイルをダウンロード
files.download("fifa_wc_2022_events.zip")

"""# 🔹4.ヒートマップ作成

１）イベントデータをDataFrame形式に変換
"""

import pandas as pd
import json
import os

# フォルダのパス
folder_path = "fifa_wc_2022_events"

# イベントデータを格納するリスト
events_data = []

# フォルダ内のすべてのJSONファイルを読み込む
for filename in os.listdir(folder_path):
    if filename.endswith(".json"):
        file_path = os.path.join(folder_path, filename)
        with open(file_path, "r", encoding="utf-8") as f:
            events = json.load(f)
            events_data.extend(events)

# DataFrameに変換
df = pd.DataFrame(events_data)

# 最初の数行を表示
print(df.head())

"""【オプション】一旦作成したヒートマップを削除する"""

import os
import glob

# 削除対象のフォルダ
output_dir = "heatmaps"

# heatmapsフォルダ内のすべてのPNGファイルを削除
files = glob.glob(os.path.join(output_dir, "*.png"))
for f in files:
  os.remove(f)

print(f"Deleted {len(files)} heatmap files from {output_dir}.")

"""【オプション】一旦散布図を作図し，正しい作図かを確認"""

import pandas as pd
import json
import os
import matplotlib.pyplot as plt

# フォルダのパス
folder_path = "fifa_wc_2022_events"
output_dir = "scatter_plots"
os.makedirs(output_dir, exist_ok=True)

# イベントデータを格納するリスト
events_data = []

# フォルダ内のすべてのJSONファイルを読み込む
for filename in os.listdir(folder_path):
    if filename.endswith(".json"):
        match_id = filename.replace(".json", "")
        file_path = os.path.join(folder_path, filename)
        with open(file_path, "r", encoding="utf-8") as f:
            events = json.load(f)
            for event in events:
                event["match_id"] = match_id
                if "player" in event:
                    event["player_id"] = event["player"]["id"]
                else:
                    event["player_id"] = None
                events_data.append(event)

# DataFrameに変換
df = pd.DataFrame(events_data)

# パスイベントのみに絞る
df = df[df['type'].apply(lambda x: x['name'] == 'Pass')]

# 各試合・各選手ごとにグループ化して処理
for (match_id, player_id), group in df.groupby(['match_id', 'player_id']):
    if len(group) < 5 or player_id is None:
        continue

    coords = group['location'].dropna().tolist()
    if not coords:
        continue

    x_coords = [c[0] for c in coords]
    y_coords = [c[1] for c in coords]

    # 散布図作成
    plt.figure(figsize=(10, 6))
    plt.scatter(x_coords, y_coords, alpha=0.6, color='blue', edgecolors='k')
    plt.title(f'Pass Scatter Plot - Match {match_id}, Player {player_id}')
    plt.xlabel('X Coordinate')
    plt.ylabel('Y Coordinate')
    plt.xlim(0, 105)
    plt.ylim(0, 68)

    # 保存
    filename = f'scatter_match_{match_id}_player_{player_id}.png'
    filepath = os.path.join(output_dir, filename)
    plt.savefig(filepath)
    plt.close()

    print(f"Saved: {filepath}")

"""【オプション】書き出した散布図をローカルに保存"""

import shutil
from google.colab import files

# 「scatter plots」フォルダをZIPファイルに圧縮
shutil.make_archive('scatter_plots', 'zip', '/content/scatter_plots')

# ZIPファイルをダウンロード
files.download('scatter_plots.zip')

"""**２）ヒートマップの作図**"""

import pandas as pd
import json
import os
import matplotlib.pyplot as plt
import seaborn as sns

# フォルダのパス
folder_path = "fifa_wc_2022_events"
output_dir = "heatmaps"
os.makedirs(output_dir, exist_ok=True)

# イベントデータを格納するリスト
events_data = []

# フォルダ内のすべてのJSONファイルを読み込む
for filename in os.listdir(folder_path):
    if filename.endswith(".json"):
        match_id = filename.replace(".json", "")
        file_path = os.path.join(folder_path, filename)
        with open(file_path, "r", encoding="utf-8") as f:
            events = json.load(f)
            for event in events:
                event["match_id"] = match_id
                if "player" in event:
                    event["player_id"] = event["player"]["id"]
                else:
                    event["player_id"] = None
                events_data.append(event)

# DataFrameに変換
df = pd.DataFrame(events_data)

# パスイベントのみに絞る
df = df[df['type'].apply(lambda x: x['name'] == 'Pass')]

# 各試合・各選手ごとにグループ化して処理
for (match_id, player_id), group in df.groupby(['match_id', 'player_id']):
    if len(group) < 5 or player_id is None:
        continue  # パスが少ない選手や不明な選手はスキップ

    coords = group['location'].dropna().tolist()
    if not coords:
        continue

    x_coords = [c[0] for c in coords]
    y_coords = [c[1] for c in coords]

    # ヒートマップ作成
    plt.figure(figsize=(10, 6))
    sns.kdeplot(x=x_coords, y=y_coords, shade=True, cmap="viridis", bw_adjust=0.5)
    plt.title(f'Pass Heatmap - Match {match_id}, Player {player_id}')
    plt.xlabel('X Coordinate')
    plt.ylabel('Y Coordinate')
    plt.xlim(0, 105) # ← 追加
    plt.ylim(0, 68) # ← 追加

    # 保存
    filename = f'pass_heatmap_match_{match_id}_player_{player_id}.png'
    filepath = os.path.join(output_dir, filename)
    plt.savefig(filepath)
    plt.close()

    print(f"Saved: {filepath}")

"""【オプション】書き出したヒートマップをローカルに保存"""

import shutil
from google.colab import files

# 「scatter plots」フォルダをZIPファイルに圧縮
shutil.make_archive('heatmaps', 'zip', '/content/heatmaps')

# ZIPファイルをダウンロード
files.download('heatmaps.zip')

"""# 🔹5.PNG画像をNumPy配列に処理

★参考資料

本プログラミングは以下のYouTubeを参考にしています。

Pythonによるディープラーニングの作り方〜画像認識〜【Python機械学習入門#10】

https://w**w**w.youtube.com/watch?v=ThKRS7B5GFY&loop=0

**★データの準備**

下記コードを実行する前に，左のファイルのところに
**[images]フォルダ**をつくり，PNG画像ファイルを保管しておきます．

① matplotlib scikit-learn pillowのインストール
"""

!pip install scipy matplotlib scikit-learn pillow

"""② 必要なライブラリのインポート"""

import os
import glob
import tensorflow as tf
import numpy as np
from PIL import Image
from scipy.cluster.hierarchy import dendrogram, linkage, fcluster
from matplotlib import pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from tqdm import tqdm

"""**★PNG画像の準備**

PNG画像を数値計算できるようにするために，Numpy配列というデータ構造に変換します．
"""

# 画像フォルダのパス
image_folder = 'heatmaps/'

# 画像ファイルのリストを取得
image_files = os.listdir(image_folder)

# 画像を格納するリスト
images = []

#データを格納するためのリストを初期化します。
X = []
y = []

#指定されたパターンに一致するすべてのファイルパスを取得します。
#ここでは、"images"フォルダ内のサブフォルダ内のPNG画像を指定しています。
#2行目以降は，画像ファイルを読み込み、デコードし、リサイズします。
#最終行は、img_data.numpy()を使用して、テンソルをNumPy配列に変換します。
for f in glob.glob("heatmaps/*.png"):
  img_data = tf.io.read_file(f)
  img_data = tf.io.decode_png(img_data)
  img_data = tf.image.resize(img_data,[100,100])
  img_data = img_data.numpy()

#データをNumPy配列に変換し、画像のピクセル値を0から1の範囲に正規化します。
#これは、ニューラルネットワークなどの機械学習モデルに入力する前に一般的な前処理手順です。
X = np.array(X) / 255.0
y = np.array(y)

"""**★ヒートマップのファイル名から試合番号と選手番号を抽出**"""

import os
import re

# 画像フォルダのパス
image_folder = 'heatmaps/'

# 画像ファイルのパスをすべて取得
image_paths = [os.path.join(image_folder, f) for f in os.listdir(image_folder) if f.endswith('.png')]

# ファイル名から試合IDと選手IDを抽出する関数
def extract_match_player_label(filename):
    match = re.search(r'match_(\d+)_player_(\d+)', filename)
    if match:
        return f"M{match.group(1)}_P{match.group(2)}"
    return filename

# ラベルの作成（ここで image_paths を使う）
labels = [extract_match_player_label(os.path.basename(path)) for path in image_paths]
print(labels)

"""**★デンドログラム（樹状図）の作成：クラスタ数の設定**"""

import os
import numpy as np
from PIL import Image
from scipy.cluster.hierarchy import linkage, dendrogram
import matplotlib.pyplot as plt
from scipy.ndimage import center_of_mass
import csv


def image_to_feature_vector(image_path):
    """
    画像を読み込んで、リサイズ後の平坦化された特徴ベクトルを返す
    """
    with Image.open(image_path) as img:
        # 画像を一定のサイズにリサイズ
        img = img.resize((64, 64))
        # 画像をNumPy配列に変換
        img_array = np.array(img)
        # 画像が複数のチャンネルを持つ場合、グレースケールに変換
        if len(img_array.shape) == 3:  # 画像が複数のチャンネルを持つか確認
            img_array = img_array.mean(axis=2)  # チャンネルを平均してグレースケールに変換
        # 画像の重み付き重心を計算
        centroid_x, centroid_y = calculate_weighted_centroid(img_array)
        # 画像のx座標平均、y座標平均を計算
        x_mean, y_mean = calculate_position_stats(img_array)
        # 画像を1次元に平坦化
        feature_vector = img_array.flatten()
        # 重心の位置情報と追加の位置情報を特徴ベクトルに追加
        feature_vector = np.append(feature_vector, [centroid_x, centroid_y, x_mean, y_mean])
        return feature_vector

def calculate_weighted_centroid(img_array):
    """
    画像の重み付き重心を計算する
    """
    centroid = center_of_mass(img_array)
    return centroid[1], centroid[0]

def calculate_position_stats(img_array):
    """
    画像のx座標平均、y座標平均を計算する
    """
    height, width = img_array.shape[:2]
    x_coords, y_coords = np.meshgrid(np.arange(width), np.arange(height))
    x_mean = np.sum(x_coords * img_array) / np.sum(img_array)
    y_mean = np.sum(y_coords * img_array) / np.sum(img_array)
    return x_mean, y_mean

# 画像フォルダのパス
image_folder = 'heatmaps/'

# 画像ファイルのパスをすべて取得
image_paths = [os.path.join(image_folder, f) for f in os.listdir(image_folder) if f.endswith('.png')]

# 画像ファイルが見つからない場合のチェック
if not image_paths:
    print("Error: No image files found in the specified folder.")
    exit()  # 実行を停止

# 特徴ベクトルのリストを作成
feature_vectors = np.array([image_to_feature_vector(image_path) for image_path in image_paths])

# 階層的クラスタリングを実行
Z = linkage(feature_vectors, 'ward')

# デンドログラムを描画
plt.figure(figsize=(20, 10))
plt.title('Hierarchical Clustering Dendrogram')
plt.xlabel('sample index')
plt.ylabel('distance')
dendrogram(
    Z,
    labels=labels, # ← ここでラベルを指定
    leaf_rotation=90.,  # x軸ラベルの回転
    leaf_font_size=8.,  # x軸ラベルのフォントサイズ
)
plt.show()

"""**★51個のクラスタに分類し，クラスタ番号を試合No,選手Noに列記する**"""

# クラスタ番号を51に設定
cluster_labels = fcluster(Z, 51, criterion='maxclust')

# CSVに保存
with open('clustering_results.csv', 'w', newline='') as f:
  writer = csv.writer(f)
  writer.writerow(['Index', 'Match_ID', 'Player_ID', 'Cluster_Label'])
  for i, (label, cluster) in enumerate(zip(labels, cluster_labels)):
    match_id, player_id = label.split('_')
    writer.writerow([i + 1, match_id, player_id, cluster])

print("クラスタリング結果を 'clustering_results.csv' に保存しました。")

# ダウンロード
files.download('clustering_results.csv')

"""**★クラスタごとにヒートマップをフォルダに格納**"""

from shutil import move
import pandas as pd
import os

# clustering_results.csv を読み込む
df = pd.read_csv('clustering_results.csv')

# クラスタごとのフォルダを作成
for cluster_num in df['Cluster_Label'].unique():
  os.makedirs(f'heatmaps/cluster_{cluster_num}', exist_ok=True)

# 各画像をクラスタフォルダに移動
for _, row in df.iterrows():
  match_id = row['Match_ID'][1:]  # 'M3869685' → '3869685'
  player_id = row['Player_ID'][1:]  # 'P29560' → '29560'

from google.colab import drive
drive.mount('/content/drive')

import os
import pandas as pd
from shutil import move

# CSVファイルの読み込み
csv_path = 'clustering_results.csv'
df = pd.read_csv(csv_path)

# 画像フォルダのパス
image_folder = 'heatmaps'

# クラスタごとのサブフォルダを作成
for cluster_num in df['Cluster_Label'].unique():
    cluster_folder = os.path.join(image_folder, f'cluster_{cluster_num}')
    os.makedirs(cluster_folder, exist_ok=True)

# 各画像をクラスタフォルダに移動
for _, row in df.iterrows():
    match_id = row['Match_ID'][1:]  # 'M3869685' → '3869685'
    player_id = row['Player_ID'][1:]  # 'P29560' → '29560'
    cluster_num = row['Cluster_Label']

    filename = f'pass_heatmap_match_{match_id}_player_{player_id}.0.png'
    src_path = os.path.join(image_folder, filename)
    dest_path = os.path.join(image_folder, f'cluster_{cluster_num}', filename)

    if os.path.exists(src_path):
        move(src_path, dest_path)
        print(f"Moved: {filename} → cluster_{cluster_num}")
    else:
        print(f"Not found: {filename}")

"""**★視認的評価を終え, 【14クラスタ】に再分類し各フォルダに収納**"""

# 1. Google Drive をマウント
from google.colab import drive
drive.mount('/content/drive')

# 2. 必要なライブラリをインポート
import pandas as pd
import os
import shutil
import matplotlib.pyplot as plt

# 3. パスの設定（Google Drive 上のパスに合わせてください）
source_base_folder = '/content/drive/MyDrive/heatmaps_51クラスタ'
target_base_folder = '/content/drive/MyDrive/heatmaps_14クラスタ'
csv_path = '/content/drive/MyDrive/clustering_results_14_split.csv'

# 4. CSVファイルの読み込み
df = pd.read_csv(csv_path)

# 5. クラスタマッピングの作成（Match_ID + Player_ID → 16クラスタ名）
cluster_map = {}
for _, row in df.iterrows():
    match_id = str(row['Match_ID']).replace('M', '').strip()
    player_id = str(row['Player_ID']).replace('P', '').strip()
    cluster_label = str(row['14Cluster']).strip()
    key = f"{match_id}_{player_id}"
    cluster_map[key] = cluster_label

# 6. 16クラスタのフォルダを作成（ポジション名付き）
os.makedirs(target_base_folder, exist_ok=True)
for cluster in set(cluster_map.values()):
    os.makedirs(os.path.join(target_base_folder, f'cluster_{cluster}'), exist_ok=True)

# 7. 画像ファイルのコピー処理
for i in range(1, 52):
    source_folder = os.path.join(source_base_folder, f'cluster_{i}')
    if not os.path.exists(source_folder):
        continue
    for file in os.listdir(source_folder):
        if file.endswith('.png'):
            parts = file.split('_')
            if len(parts) >= 6:
                match_id = parts[3]
                player_id = parts[5].split('.')[0]
                key = f"{match_id}_{player_id}"
                if key in cluster_map:
                    target_cluster = cluster_map[key]
                    target_folder = os.path.join(target_base_folder, f'cluster_{target_cluster}')
                    shutil.copy(os.path.join(source_folder, file), os.path.join(target_folder, file))

# 8. クラスタごとの画像枚数をカウント
cluster_counts = {}
for cluster in sorted(set(cluster_map.values())):
    folder_path = os.path.join(target_base_folder, f'cluster_{cluster}')
    if os.path.exists(folder_path):
        count = len([f for f in os.listdir(folder_path) if f.endswith('.png')])
        cluster_counts[cluster] = count

# 9. 結果の表示
print("クラスタごとの画像枚数:")
for cluster, count in cluster_counts.items():
    print(f"cluster_{cluster}: {count} 枚")

# 10. 可視化（棒グラフ）
plt.figure(figsize=(12, 6))
plt.bar(cluster_counts.keys(), cluster_counts.values(), color='skyblue')
plt.xlabel('Cluster')
plt.ylabel('Number of Images')
plt.title('Number of Images per 16 Clusters')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()