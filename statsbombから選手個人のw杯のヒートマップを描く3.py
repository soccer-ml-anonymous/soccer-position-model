# -*- coding: utf-8 -*-
"""StatsBombã‹ã‚‰é¸æ‰‹å€‹äººã®Wæ¯ã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ•ã‚šã‚’æã3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KqpJNR3HeR0WHxMN4U0QSUSDq0m1zyK8

# ğŸ”¹ 1. å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
"""

!pip install statsbombpy kloppy seaborn matplotlib pandas

"""# ğŸ”¹2.Statsbomb open dataã«å«ã¾ã‚Œã‚‹å¤§ä¼šã‚’å‡ºåŠ›ã—ã¦ç¢ºèªã™

"""

import pandas as pd
import requests

# StatsBomb Open Dataã®competitions.jsonã®URL
url = "https://raw.githubusercontent.com/statsbomb/open-data/master/data/competitions.json"

# JSONãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
response = requests.get(url)
competitions = response.json()

# pandasã§DataFrameã«å¤‰æ›
df = pd.DataFrame(competitions)

# å¿…è¦ãªã‚«ãƒ©ãƒ ã ã‘æŠ½å‡ºï¼ˆä»»æ„ï¼‰
df = df[["competition_id", "season_id", "competition_name", "country_name", "season_name"]]

# CSVã¨ã—ã¦ä¿å­˜
df.to_csv("competitions.csv", index=False)

# è¡¨ç¤ºï¼ˆç¢ºèªç”¨ï¼‰
df.head()

"""# ğŸ”¹ 3. Wæ¯ã®IDã‚’ç¢ºèªã—ã¦ã‚¤ãƒ™ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—


"""

import requests
import os
import json
from tqdm import tqdm

# æ­£ã—ã„ID
competition_id = 43
season_id = 106

# è©¦åˆä¸€è¦§ã‚’å–å¾—
matches_url = f"https://raw.githubusercontent.com/statsbomb/open-data/master/data/matches/{competition_id}/{season_id}.json"
matches = requests.get(matches_url).json()

# ä¿å­˜ãƒ•ã‚©ãƒ«ãƒ€ä½œæˆ
os.makedirs("fifa_wc_2022_events", exist_ok=True)

# å„è©¦åˆã®ã‚¤ãƒ™ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
for match in tqdm(matches):
    match_id = match["match_id"]
    events_url = f"https://raw.githubusercontent.com/statsbomb/open-data/master/data/events/{match_id}.json"
    events = requests.get(events_url).json()

    # JSONã¨ã—ã¦ä¿å­˜
    with open(f"fifa_wc_2022_events/{match_id}.json", "w") as f:
        json.dump(events, f)

print("å…¨è©¦åˆã®ã‚¤ãƒ™ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")

import shutil

# ãƒ•ã‚©ãƒ«ãƒ€ã‚’ZIPãƒ•ã‚¡ã‚¤ãƒ«ã«åœ§ç¸®
shutil.make_archive("fifa_wc_2022_events", 'zip', "fifa_wc_2022_events")
from google.colab import files
# ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
files.download("fifa_wc_2022_events.zip")

"""# ğŸ”¹4.ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ä½œæˆ

ï¼‘ï¼‰ã‚¤ãƒ™ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’DataFrameå½¢å¼ã«å¤‰æ›
"""

import pandas as pd
import json
import os

# ãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹
folder_path = "fifa_wc_2022_events"

# ã‚¤ãƒ™ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æ ¼ç´ã™ã‚‹ãƒªã‚¹ãƒˆ
events_data = []

# ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ã™ã¹ã¦ã®JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
for filename in os.listdir(folder_path):
    if filename.endswith(".json"):
        file_path = os.path.join(folder_path, filename)
        with open(file_path, "r", encoding="utf-8") as f:
            events = json.load(f)
            events_data.extend(events)

# DataFrameã«å¤‰æ›
df = pd.DataFrame(events_data)

# æœ€åˆã®æ•°è¡Œã‚’è¡¨ç¤º
print(df.head())

"""ã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã€‘ä¸€æ—¦ä½œæˆã—ãŸãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’å‰Šé™¤ã™ã‚‹"""

import os
import glob

# å‰Šé™¤å¯¾è±¡ã®ãƒ•ã‚©ãƒ«ãƒ€
output_dir = "heatmaps"

# heatmapsãƒ•ã‚©ãƒ«ãƒ€å†…ã®ã™ã¹ã¦ã®PNGãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
files = glob.glob(os.path.join(output_dir, "*.png"))
for f in files:
  os.remove(f)

print(f"Deleted {len(files)} heatmap files from {output_dir}.")

"""ã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã€‘ä¸€æ—¦æ•£å¸ƒå›³ã‚’ä½œå›³ã—ï¼Œæ­£ã—ã„ä½œå›³ã‹ã‚’ç¢ºèª"""

import pandas as pd
import json
import os
import matplotlib.pyplot as plt

# ãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹
folder_path = "fifa_wc_2022_events"
output_dir = "scatter_plots"
os.makedirs(output_dir, exist_ok=True)

# ã‚¤ãƒ™ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æ ¼ç´ã™ã‚‹ãƒªã‚¹ãƒˆ
events_data = []

# ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ã™ã¹ã¦ã®JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
for filename in os.listdir(folder_path):
    if filename.endswith(".json"):
        match_id = filename.replace(".json", "")
        file_path = os.path.join(folder_path, filename)
        with open(file_path, "r", encoding="utf-8") as f:
            events = json.load(f)
            for event in events:
                event["match_id"] = match_id
                if "player" in event:
                    event["player_id"] = event["player"]["id"]
                else:
                    event["player_id"] = None
                events_data.append(event)

# DataFrameã«å¤‰æ›
df = pd.DataFrame(events_data)

# ãƒ‘ã‚¹ã‚¤ãƒ™ãƒ³ãƒˆã®ã¿ã«çµã‚‹
df = df[df['type'].apply(lambda x: x['name'] == 'Pass')]

# å„è©¦åˆãƒ»å„é¸æ‰‹ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã¦å‡¦ç†
for (match_id, player_id), group in df.groupby(['match_id', 'player_id']):
    if len(group) < 5 or player_id is None:
        continue

    coords = group['location'].dropna().tolist()
    if not coords:
        continue

    x_coords = [c[0] for c in coords]
    y_coords = [c[1] for c in coords]

    # æ•£å¸ƒå›³ä½œæˆ
    plt.figure(figsize=(10, 6))
    plt.scatter(x_coords, y_coords, alpha=0.6, color='blue', edgecolors='k')
    plt.title(f'Pass Scatter Plot - Match {match_id}, Player {player_id}')
    plt.xlabel('X Coordinate')
    plt.ylabel('Y Coordinate')
    plt.xlim(0, 105)
    plt.ylim(0, 68)

    # ä¿å­˜
    filename = f'scatter_match_{match_id}_player_{player_id}.png'
    filepath = os.path.join(output_dir, filename)
    plt.savefig(filepath)
    plt.close()

    print(f"Saved: {filepath}")

"""ã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã€‘æ›¸ãå‡ºã—ãŸæ•£å¸ƒå›³ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã«ä¿å­˜"""

import shutil
from google.colab import files

# ã€Œscatter plotsã€ãƒ•ã‚©ãƒ«ãƒ€ã‚’ZIPãƒ•ã‚¡ã‚¤ãƒ«ã«åœ§ç¸®
shutil.make_archive('scatter_plots', 'zip', '/content/scatter_plots')

# ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
files.download('scatter_plots.zip')

"""**ï¼’ï¼‰ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã®ä½œå›³**"""

import pandas as pd
import json
import os
import matplotlib.pyplot as plt
import seaborn as sns

# ãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹
folder_path = "fifa_wc_2022_events"
output_dir = "heatmaps"
os.makedirs(output_dir, exist_ok=True)

# ã‚¤ãƒ™ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æ ¼ç´ã™ã‚‹ãƒªã‚¹ãƒˆ
events_data = []

# ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ã™ã¹ã¦ã®JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
for filename in os.listdir(folder_path):
    if filename.endswith(".json"):
        match_id = filename.replace(".json", "")
        file_path = os.path.join(folder_path, filename)
        with open(file_path, "r", encoding="utf-8") as f:
            events = json.load(f)
            for event in events:
                event["match_id"] = match_id
                if "player" in event:
                    event["player_id"] = event["player"]["id"]
                else:
                    event["player_id"] = None
                events_data.append(event)

# DataFrameã«å¤‰æ›
df = pd.DataFrame(events_data)

# ãƒ‘ã‚¹ã‚¤ãƒ™ãƒ³ãƒˆã®ã¿ã«çµã‚‹
df = df[df['type'].apply(lambda x: x['name'] == 'Pass')]

# å„è©¦åˆãƒ»å„é¸æ‰‹ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã¦å‡¦ç†
for (match_id, player_id), group in df.groupby(['match_id', 'player_id']):
    if len(group) < 5 or player_id is None:
        continue  # ãƒ‘ã‚¹ãŒå°‘ãªã„é¸æ‰‹ã‚„ä¸æ˜ãªé¸æ‰‹ã¯ã‚¹ã‚­ãƒƒãƒ—

    coords = group['location'].dropna().tolist()
    if not coords:
        continue

    x_coords = [c[0] for c in coords]
    y_coords = [c[1] for c in coords]

    # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ä½œæˆ
    plt.figure(figsize=(10, 6))
    sns.kdeplot(x=x_coords, y=y_coords, shade=True, cmap="viridis", bw_adjust=0.5)
    plt.title(f'Pass Heatmap - Match {match_id}, Player {player_id}')
    plt.xlabel('X Coordinate')
    plt.ylabel('Y Coordinate')
    plt.xlim(0, 105) # â† è¿½åŠ 
    plt.ylim(0, 68) # â† è¿½åŠ 

    # ä¿å­˜
    filename = f'pass_heatmap_match_{match_id}_player_{player_id}.png'
    filepath = os.path.join(output_dir, filename)
    plt.savefig(filepath)
    plt.close()

    print(f"Saved: {filepath}")

"""ã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã€‘æ›¸ãå‡ºã—ãŸãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã«ä¿å­˜"""

import shutil
from google.colab import files

# ã€Œscatter plotsã€ãƒ•ã‚©ãƒ«ãƒ€ã‚’ZIPãƒ•ã‚¡ã‚¤ãƒ«ã«åœ§ç¸®
shutil.make_archive('heatmaps', 'zip', '/content/heatmaps')

# ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
files.download('heatmaps.zip')

"""# ğŸ”¹5.PNGç”»åƒã‚’NumPyé…åˆ—ã«å‡¦ç†

â˜…å‚è€ƒè³‡æ–™

æœ¬ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã¯ä»¥ä¸‹ã®YouTubeã‚’å‚è€ƒã«ã—ã¦ã„ã¾ã™ã€‚

Pythonã«ã‚ˆã‚‹ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã®ä½œã‚Šæ–¹ã€œç”»åƒèªè­˜ã€œã€Pythonæ©Ÿæ¢°å­¦ç¿’å…¥é–€#10ã€‘

https://w**w**w.youtube.com/watch?v=ThKRS7B5GFY&loop=0

**â˜…ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™**

ä¸‹è¨˜ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã™ã‚‹å‰ã«ï¼Œå·¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¨ã“ã‚ã«
**[images]ãƒ•ã‚©ãƒ«ãƒ€**ã‚’ã¤ãã‚Šï¼ŒPNGç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿ç®¡ã—ã¦ãŠãã¾ã™ï¼

â‘  matplotlib scikit-learn pillowã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
"""

!pip install scipy matplotlib scikit-learn pillow

"""â‘¡ å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"""

import os
import glob
import tensorflow as tf
import numpy as np
from PIL import Image
from scipy.cluster.hierarchy import dendrogram, linkage, fcluster
from matplotlib import pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from tqdm import tqdm

"""**â˜…PNGç”»åƒã®æº–å‚™**

PNGç”»åƒã‚’æ•°å€¤è¨ˆç®—ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ãŸã‚ã«ï¼ŒNumpyé…åˆ—ã¨ã„ã†ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã«å¤‰æ›ã—ã¾ã™ï¼
"""

# ç”»åƒãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹
image_folder = 'heatmaps/'

# ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¹ãƒˆã‚’å–å¾—
image_files = os.listdir(image_folder)

# ç”»åƒã‚’æ ¼ç´ã™ã‚‹ãƒªã‚¹ãƒˆ
images = []

#ãƒ‡ãƒ¼ã‚¿ã‚’æ ¼ç´ã™ã‚‹ãŸã‚ã®ãƒªã‚¹ãƒˆã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚
X = []
y = []

#æŒ‡å®šã•ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³ã«ä¸€è‡´ã™ã‚‹ã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å–å¾—ã—ã¾ã™ã€‚
#ã“ã“ã§ã¯ã€"images"ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€å†…ã®PNGç”»åƒã‚’æŒ‡å®šã—ã¦ã„ã¾ã™ã€‚
#2è¡Œç›®ä»¥é™ã¯ï¼Œç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€ãƒ‡ã‚³ãƒ¼ãƒ‰ã—ã€ãƒªã‚µã‚¤ã‚ºã—ã¾ã™ã€‚
#æœ€çµ‚è¡Œã¯ã€img_data.numpy()ã‚’ä½¿ç”¨ã—ã¦ã€ãƒ†ãƒ³ã‚½ãƒ«ã‚’NumPyé…åˆ—ã«å¤‰æ›ã—ã¾ã™ã€‚
for f in glob.glob("heatmaps/*.png"):
  img_data = tf.io.read_file(f)
  img_data = tf.io.decode_png(img_data)
  img_data = tf.image.resize(img_data,[100,100])
  img_data = img_data.numpy()

#ãƒ‡ãƒ¼ã‚¿ã‚’NumPyé…åˆ—ã«å¤‰æ›ã—ã€ç”»åƒã®ãƒ”ã‚¯ã‚»ãƒ«å€¤ã‚’0ã‹ã‚‰1ã®ç¯„å›²ã«æ­£è¦åŒ–ã—ã¾ã™ã€‚
#ã“ã‚Œã¯ã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãªã©ã®æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã«å…¥åŠ›ã™ã‚‹å‰ã«ä¸€èˆ¬çš„ãªå‰å‡¦ç†æ‰‹é †ã§ã™ã€‚
X = np.array(X) / 255.0
y = np.array(y)

"""**â˜…ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã®ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰è©¦åˆç•ªå·ã¨é¸æ‰‹ç•ªå·ã‚’æŠ½å‡º**"""

import os
import re

# ç”»åƒãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹
image_folder = 'heatmaps/'

# ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’ã™ã¹ã¦å–å¾—
image_paths = [os.path.join(image_folder, f) for f in os.listdir(image_folder) if f.endswith('.png')]

# ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰è©¦åˆIDã¨é¸æ‰‹IDã‚’æŠ½å‡ºã™ã‚‹é–¢æ•°
def extract_match_player_label(filename):
    match = re.search(r'match_(\d+)_player_(\d+)', filename)
    if match:
        return f"M{match.group(1)}_P{match.group(2)}"
    return filename

# ãƒ©ãƒ™ãƒ«ã®ä½œæˆï¼ˆã“ã“ã§ image_paths ã‚’ä½¿ã†ï¼‰
labels = [extract_match_player_label(os.path.basename(path)) for path in image_paths]
print(labels)

"""**â˜…ãƒ‡ãƒ³ãƒ‰ãƒ­ã‚°ãƒ©ãƒ ï¼ˆæ¨¹çŠ¶å›³ï¼‰ã®ä½œæˆï¼šã‚¯ãƒ©ã‚¹ã‚¿æ•°ã®è¨­å®š**"""

import os
import numpy as np
from PIL import Image
from scipy.cluster.hierarchy import linkage, dendrogram
import matplotlib.pyplot as plt
from scipy.ndimage import center_of_mass
import csv


def image_to_feature_vector(image_path):
    """
    ç”»åƒã‚’èª­ã¿è¾¼ã‚“ã§ã€ãƒªã‚µã‚¤ã‚ºå¾Œã®å¹³å¦åŒ–ã•ã‚ŒãŸç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ã‚’è¿”ã™
    """
    with Image.open(image_path) as img:
        # ç”»åƒã‚’ä¸€å®šã®ã‚µã‚¤ã‚ºã«ãƒªã‚µã‚¤ã‚º
        img = img.resize((64, 64))
        # ç”»åƒã‚’NumPyé…åˆ—ã«å¤‰æ›
        img_array = np.array(img)
        # ç”»åƒãŒè¤‡æ•°ã®ãƒãƒ£ãƒ³ãƒãƒ«ã‚’æŒã¤å ´åˆã€ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ã«å¤‰æ›
        if len(img_array.shape) == 3:  # ç”»åƒãŒè¤‡æ•°ã®ãƒãƒ£ãƒ³ãƒãƒ«ã‚’æŒã¤ã‹ç¢ºèª
            img_array = img_array.mean(axis=2)  # ãƒãƒ£ãƒ³ãƒãƒ«ã‚’å¹³å‡ã—ã¦ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ã«å¤‰æ›
        # ç”»åƒã®é‡ã¿ä»˜ãé‡å¿ƒã‚’è¨ˆç®—
        centroid_x, centroid_y = calculate_weighted_centroid(img_array)
        # ç”»åƒã®xåº§æ¨™å¹³å‡ã€yåº§æ¨™å¹³å‡ã‚’è¨ˆç®—
        x_mean, y_mean = calculate_position_stats(img_array)
        # ç”»åƒã‚’1æ¬¡å…ƒã«å¹³å¦åŒ–
        feature_vector = img_array.flatten()
        # é‡å¿ƒã®ä½ç½®æƒ…å ±ã¨è¿½åŠ ã®ä½ç½®æƒ…å ±ã‚’ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ã«è¿½åŠ 
        feature_vector = np.append(feature_vector, [centroid_x, centroid_y, x_mean, y_mean])
        return feature_vector

def calculate_weighted_centroid(img_array):
    """
    ç”»åƒã®é‡ã¿ä»˜ãé‡å¿ƒã‚’è¨ˆç®—ã™ã‚‹
    """
    centroid = center_of_mass(img_array)
    return centroid[1], centroid[0]

def calculate_position_stats(img_array):
    """
    ç”»åƒã®xåº§æ¨™å¹³å‡ã€yåº§æ¨™å¹³å‡ã‚’è¨ˆç®—ã™ã‚‹
    """
    height, width = img_array.shape[:2]
    x_coords, y_coords = np.meshgrid(np.arange(width), np.arange(height))
    x_mean = np.sum(x_coords * img_array) / np.sum(img_array)
    y_mean = np.sum(y_coords * img_array) / np.sum(img_array)
    return x_mean, y_mean

# ç”»åƒãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹
image_folder = 'heatmaps/'

# ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’ã™ã¹ã¦å–å¾—
image_paths = [os.path.join(image_folder, f) for f in os.listdir(image_folder) if f.endswith('.png')]

# ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã®ãƒã‚§ãƒƒã‚¯
if not image_paths:
    print("Error: No image files found in the specified folder.")
    exit()  # å®Ÿè¡Œã‚’åœæ­¢

# ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ã®ãƒªã‚¹ãƒˆã‚’ä½œæˆ
feature_vectors = np.array([image_to_feature_vector(image_path) for image_path in image_paths])

# éšå±¤çš„ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã‚’å®Ÿè¡Œ
Z = linkage(feature_vectors, 'ward')

# ãƒ‡ãƒ³ãƒ‰ãƒ­ã‚°ãƒ©ãƒ ã‚’æç”»
plt.figure(figsize=(20, 10))
plt.title('Hierarchical Clustering Dendrogram')
plt.xlabel('sample index')
plt.ylabel('distance')
dendrogram(
    Z,
    labels=labels, # â† ã“ã“ã§ãƒ©ãƒ™ãƒ«ã‚’æŒ‡å®š
    leaf_rotation=90.,  # xè»¸ãƒ©ãƒ™ãƒ«ã®å›è»¢
    leaf_font_size=8.,  # xè»¸ãƒ©ãƒ™ãƒ«ã®ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚º
)
plt.show()

"""**â˜…51å€‹ã®ã‚¯ãƒ©ã‚¹ã‚¿ã«åˆ†é¡ã—ï¼Œã‚¯ãƒ©ã‚¹ã‚¿ç•ªå·ã‚’è©¦åˆNo,é¸æ‰‹Noã«åˆ—è¨˜ã™ã‚‹**"""

# ã‚¯ãƒ©ã‚¹ã‚¿ç•ªå·ã‚’51ã«è¨­å®š
cluster_labels = fcluster(Z, 51, criterion='maxclust')

# CSVã«ä¿å­˜
with open('clustering_results.csv', 'w', newline='') as f:
  writer = csv.writer(f)
  writer.writerow(['Index', 'Match_ID', 'Player_ID', 'Cluster_Label'])
  for i, (label, cluster) in enumerate(zip(labels, cluster_labels)):
    match_id, player_id = label.split('_')
    writer.writerow([i + 1, match_id, player_id, cluster])

print("ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœã‚’ 'clustering_results.csv' ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")

# ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
files.download('clustering_results.csv')

"""**â˜…ã‚¯ãƒ©ã‚¹ã‚¿ã”ã¨ã«ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’ãƒ•ã‚©ãƒ«ãƒ€ã«æ ¼ç´**"""

from shutil import move
import pandas as pd
import os

# clustering_results.csv ã‚’èª­ã¿è¾¼ã‚€
df = pd.read_csv('clustering_results.csv')

# ã‚¯ãƒ©ã‚¹ã‚¿ã”ã¨ã®ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ
for cluster_num in df['Cluster_Label'].unique():
  os.makedirs(f'heatmaps/cluster_{cluster_num}', exist_ok=True)

# å„ç”»åƒã‚’ã‚¯ãƒ©ã‚¹ã‚¿ãƒ•ã‚©ãƒ«ãƒ€ã«ç§»å‹•
for _, row in df.iterrows():
  match_id = row['Match_ID'][1:]  # 'M3869685' â†’ '3869685'
  player_id = row['Player_ID'][1:]  # 'P29560' â†’ '29560'

from google.colab import drive
drive.mount('/content/drive')

import os
import pandas as pd
from shutil import move

# CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
csv_path = 'clustering_results.csv'
df = pd.read_csv(csv_path)

# ç”»åƒãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹
image_folder = 'heatmaps'

# ã‚¯ãƒ©ã‚¹ã‚¿ã”ã¨ã®ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ
for cluster_num in df['Cluster_Label'].unique():
    cluster_folder = os.path.join(image_folder, f'cluster_{cluster_num}')
    os.makedirs(cluster_folder, exist_ok=True)

# å„ç”»åƒã‚’ã‚¯ãƒ©ã‚¹ã‚¿ãƒ•ã‚©ãƒ«ãƒ€ã«ç§»å‹•
for _, row in df.iterrows():
    match_id = row['Match_ID'][1:]  # 'M3869685' â†’ '3869685'
    player_id = row['Player_ID'][1:]  # 'P29560' â†’ '29560'
    cluster_num = row['Cluster_Label']

    filename = f'pass_heatmap_match_{match_id}_player_{player_id}.0.png'
    src_path = os.path.join(image_folder, filename)
    dest_path = os.path.join(image_folder, f'cluster_{cluster_num}', filename)

    if os.path.exists(src_path):
        move(src_path, dest_path)
        print(f"Moved: {filename} â†’ cluster_{cluster_num}")
    else:
        print(f"Not found: {filename}")

"""**â˜…è¦–èªçš„è©•ä¾¡ã‚’çµ‚ãˆ, ã€14ã‚¯ãƒ©ã‚¹ã‚¿ã€‘ã«å†åˆ†é¡ã—å„ãƒ•ã‚©ãƒ«ãƒ€ã«åç´**"""

# 1. Google Drive ã‚’ãƒã‚¦ãƒ³ãƒˆ
from google.colab import drive
drive.mount('/content/drive')

# 2. å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import pandas as pd
import os
import shutil
import matplotlib.pyplot as plt

# 3. ãƒ‘ã‚¹ã®è¨­å®šï¼ˆGoogle Drive ä¸Šã®ãƒ‘ã‚¹ã«åˆã‚ã›ã¦ãã ã•ã„ï¼‰
source_base_folder = '/content/drive/MyDrive/heatmaps_51ã‚¯ãƒ©ã‚¹ã‚¿'
target_base_folder = '/content/drive/MyDrive/heatmaps_14ã‚¯ãƒ©ã‚¹ã‚¿'
csv_path = '/content/drive/MyDrive/clustering_results_14_split.csv'

# 4. CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
df = pd.read_csv(csv_path)

# 5. ã‚¯ãƒ©ã‚¹ã‚¿ãƒãƒƒãƒ”ãƒ³ã‚°ã®ä½œæˆï¼ˆMatch_ID + Player_ID â†’ 16ã‚¯ãƒ©ã‚¹ã‚¿åï¼‰
cluster_map = {}
for _, row in df.iterrows():
    match_id = str(row['Match_ID']).replace('M', '').strip()
    player_id = str(row['Player_ID']).replace('P', '').strip()
    cluster_label = str(row['14Cluster']).strip()
    key = f"{match_id}_{player_id}"
    cluster_map[key] = cluster_label

# 6. 16ã‚¯ãƒ©ã‚¹ã‚¿ã®ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆï¼ˆãƒã‚¸ã‚·ãƒ§ãƒ³åä»˜ãï¼‰
os.makedirs(target_base_folder, exist_ok=True)
for cluster in set(cluster_map.values()):
    os.makedirs(os.path.join(target_base_folder, f'cluster_{cluster}'), exist_ok=True)

# 7. ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚³ãƒ”ãƒ¼å‡¦ç†
for i in range(1, 52):
    source_folder = os.path.join(source_base_folder, f'cluster_{i}')
    if not os.path.exists(source_folder):
        continue
    for file in os.listdir(source_folder):
        if file.endswith('.png'):
            parts = file.split('_')
            if len(parts) >= 6:
                match_id = parts[3]
                player_id = parts[5].split('.')[0]
                key = f"{match_id}_{player_id}"
                if key in cluster_map:
                    target_cluster = cluster_map[key]
                    target_folder = os.path.join(target_base_folder, f'cluster_{target_cluster}')
                    shutil.copy(os.path.join(source_folder, file), os.path.join(target_folder, file))

# 8. ã‚¯ãƒ©ã‚¹ã‚¿ã”ã¨ã®ç”»åƒæšæ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
cluster_counts = {}
for cluster in sorted(set(cluster_map.values())):
    folder_path = os.path.join(target_base_folder, f'cluster_{cluster}')
    if os.path.exists(folder_path):
        count = len([f for f in os.listdir(folder_path) if f.endswith('.png')])
        cluster_counts[cluster] = count

# 9. çµæœã®è¡¨ç¤º
print("ã‚¯ãƒ©ã‚¹ã‚¿ã”ã¨ã®ç”»åƒæšæ•°:")
for cluster, count in cluster_counts.items():
    print(f"cluster_{cluster}: {count} æš")

# 10. å¯è¦–åŒ–ï¼ˆæ£’ã‚°ãƒ©ãƒ•ï¼‰
plt.figure(figsize=(12, 6))
plt.bar(cluster_counts.keys(), cluster_counts.values(), color='skyblue')
plt.xlabel('Cluster')
plt.ylabel('Number of Images')
plt.title('Number of Images per 16 Clusters')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()